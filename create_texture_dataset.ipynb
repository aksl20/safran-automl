{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_texture_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNtRo7eThse0YED3q9nK+rw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksl20/safran-automl/blob/dataset/create_texture_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWI6QbsoF3nd",
        "colab_type": "text"
      },
      "source": [
        "# New texture images dataset\n",
        "\n",
        "This dataset relies on  the anomaly detection  dataset proposed by MVTEC, and use textile texture from the carpet dataset. \n",
        "Originally, the main goal of the dataset is to design anomaly detection algorithm using only sample with defects. For experimental purposes, we propose to use to use this dataset as a classification task using patches sampled in the test data, using this classes :\n",
        " * good\n",
        " * color\n",
        " * cut\n",
        " * good\n",
        " * hole\n",
        " * thread\n",
        " * metal_contamination\n",
        "\n",
        "\n",
        "## Dataset creation methodology\n",
        "\n",
        "As the test set of the original dataset contains few defect samples, we propose a simple and quick  method to add artificial samples using simple transformation: rotations and flips.\n",
        "\n",
        "The classification dataset is created different configurations as follows:\n",
        "* For each class generate described above, we generate images using a rotation angle of the patch from 0 to 150 degree.\n",
        "\n",
        "This results in 40 different combination that are all used and stored\n",
        "\n",
        "This is done for all patches, such that for good samples we only keep 100 samples per parameter configurations, and for defect images we keep samples where at least  10% of the patch contains a defetc zone(according to the mask of defect images)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLpHPWeILTXK",
        "colab_type": "code",
        "outputId": "b394eb51-f762-40bc-98c2-41c8ecafbdee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import os, glob\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.ndimage import map_coordinates\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import seaborn as sns\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7l_HoELNyrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/SSL-research\" #@param {type:\"string\"}\n",
        "dataset_name = \"carpet\" #@param [\"carpet\"]\n",
        "data_root = os.path.join(root,'www/')\n",
        "dataset_path = os.path.join(data_root, dataset_name)\n",
        "if os.path.exists(os.path.join(data_root,dataset_name)) and len(os.listdir(data_root))>0:\n",
        "    pass\n",
        "else:\n",
        "    url = f'ftp://guest:GU.205dldo@ftp.softronics.ch/mvtec_anomaly_detection/{dataset_name}.tar.xz'\n",
        "    !wget -N $url\n",
        "    tarfile = f'{dataset_name}.tar.xz'\n",
        "    !tar -xJf  $tarfile\n",
        "    !rm  -rf $tarfile\n",
        "    if not os.path.exists(data_root): os.makedirs(data_root)\n",
        "    path_data = f'/content/{dataset_name}'\n",
        "    print(data_root)\n",
        "    !mv $path_data \"$data_root\"\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE07UVBzjhNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "import h5py\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torchvision import transforms,utils\n",
        "\n",
        "import contextlib\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V84xxUDp6uMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class PatchManager(object):\n",
        "    def __init__(self,img_size, patch_shape=None, stride=None, centers_list=None):\n",
        "        self.img_size = img_size\n",
        "        assert (patch_shape[0]%2==0) and (patch_shape[1]%2==0), \"the patch shapes must be define with even number\"\n",
        "        self.patch_shape = patch_shape if patch_shape is not None else (64,64)\n",
        "        self.h,self.w = self.patch_shape\n",
        "        self.stride = stride if stride is not None else (32,32)\n",
        "        self.center_list = centers_list if isinstance(centers_list, np.ndarray) else PatchManager.get_center_lists_grid(img_shape=self.img_size, stride=stride)\n",
        "        self.fh,self.fw = int(np.floor(self.h/2)), int(np.floor(self.w/2))\n",
        "    @staticmethod\n",
        "    def get_center_lists_grid(img_shape,stride):\n",
        "        x = np.linspace(stride[0], img_shape[0]-stride[0],(img_shape[0]-stride[0])// stride[0])\n",
        "        y = np.linspace(stride[1], img_shape[1]-stride[1],(img_shape[1]-stride[1])// stride[0])\n",
        "        X,Y = np.meshgrid(x,y)\n",
        "        centers = np.hstack((X.ravel().reshape(-1,1), Y.ravel().reshape(-1,1))).astype(int)\n",
        "        return centers\n",
        "    @staticmethod\n",
        "    def get_rotation_matrix(angle):\n",
        "        theta = np.radians(angle)\n",
        "        c, s = np.cos(theta), np.sin(theta)\n",
        "        return np.array(((c, -s), (s, c)))\n",
        "    def get_patch(self, img, center_point, angle=0):\n",
        "        center_row, center_col = center_point\n",
        "        h,w = self.patch_shape\n",
        "        ty = np.arange(center_col-self.fh, center_col+self.fh)\n",
        "        tx = np.arange(center_row-self.fw, center_row+self.fw)\n",
        "        rotatex, rotatey= np.meshgrid(tx,ty)\n",
        "        coords   = [rotatex.reshape((1,h*w))-center_row, rotatey.reshape((1,h*w))-center_col]\n",
        "        coords = np.asarray(coords).reshape(2,h*w)\n",
        "        rotatedcoords = np.matmul(PatchManager.get_rotation_matrix(angle), coords)\n",
        "        return map_coordinates(img, [rotatedcoords[1]+center_col, rotatedcoords[0]+center_row], order=1, mode='mirror').reshape(h,w)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvr4crWkMi3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_folder, problem='carpet', datatype='train', img_size=None, patch_shape=None, stride=None,\n",
        "                 test_example='hole', processed_root_folder=None,\n",
        "                 sample_size=None, transform=None,download=True,angle=0,vflip=False,hflip=False,split=None):\n",
        "        \"\"\"\n",
        "        # steps for initialization\n",
        "        - first check that the root folder exists\n",
        "        - check that image exists and make the list of imgs\n",
        "        - create a PatchManager and generate centerlist\n",
        "        \"\"\"\n",
        "        \n",
        "\n",
        "        \n",
        "        self.angle=angle\n",
        "        self.split=split\n",
        "        self.datatype = datatype\n",
        "        self.img_size = (512, 512) if img_size is None else img_size\n",
        "        self.patch_shape = (64, 64) if patch_shape is None else patch_shape\n",
        "        self.stride = (40, 40) if stride is None else stride\n",
        "        self.pm = PatchManager(img_size=self.img_size, patch_shape=self.patch_shape, stride=self.stride)\n",
        "        self.process_data(datatype, self.img_size, self.patch_shape, problem, processed_root_folder, root_folder, self.stride,\n",
        "                          test_example)\n",
        "        # print(split)\n",
        "        # print(self.data.shape)\n",
        "        # print(self.mask.shape)\n",
        "        self.data = self.data[:]\n",
        "        self.mask = self.mask[:] if test_example != 'good' else None\n",
        "        isplit_train = int(0.7 * self.data.shape[0])\n",
        "        if split == 'train':\n",
        "            self.data = self.data[:isplit_train]\n",
        "            self.mask = self.mask[:isplit_train] if test_example != 'good' else None\n",
        "        else:\n",
        "            self.data = self.data[isplit_train:]\n",
        "            self.mask = self.mask[isplit_train:] if test_example != 'good' else None\n",
        "        # print(split,self.data.shape)\n",
        "        # return\n",
        "        # print(self.mask.shape)\n",
        "\n",
        "        self.transform = transforms.Compose([ transforms.ToTensor()]) if transform is None else transform\n",
        "        # randstate = 5000*(angle+1)\n",
        "        # if split in ['train','test']:\n",
        "        #     self.split_train_test(test_example=test_example,randstate=randstate)\n",
        "        \n",
        "\n",
        "        self.sample_size = sample_size\n",
        "        self.resample_info()\n",
        "        \n",
        "\n",
        "    @contextlib.contextmanager\n",
        "    def split_train_test(self, test_example,randstate):\n",
        "        state = np.random.get_state()\n",
        "    \n",
        "        print(self.datatype, test_example,'split{}'.format(self.split))\n",
        "\n",
        "        datatype = ['good', 'color', 'cut', 'good', 'hole', 'thread', 'metal_contamination']\n",
        "        tmpdtype = 'good' if self.datatype=='train' else test_example\n",
        "        i = self.data.shape[0]\n",
        "        pos = datatype.index(tmpdtype)\n",
        "        np.random.seed(pos+randstate)\n",
        "        indexes = np.random.choice(np.arange(i), int(i*0.7),replace=False)\n",
        "        trainindexes = np.sort(indexes)\n",
        "        testindexes = np.sort(np.array([ii for ii in np.arange(i) if ii not in trainindexes]))\n",
        "        if self.split=='train':\n",
        "            self.data = self.data[:][trainindexes]\n",
        "            self.mask = self.mask[:][trainindexes] if test_example !='good'  else None\n",
        "        else:\n",
        "            self.data = self.data[:][testindexes]\n",
        "            self.mask = self.mask[:][testindexes] if test_example !='good'  else None\n",
        "\n",
        "        np.random.set_state(state)\n",
        "\n",
        "\n",
        "    def resample_info(self):\n",
        "        self.dfinfo = self.create_sample_list()\n",
        "        self.dfinfo = self.dfinfo.sample( self.sample_size if (self.sample_size is not None) and int(self.sample_size < self.dfinfo.shape[0]) else self.dfinfo.shape[\n",
        "                0], replace=False)\n",
        "        \n",
        "    def process_data(self, datatype, img_size, patch_shape, problem, processed_root_folder, root_folder, stride,\n",
        "                     test_example):\n",
        "        # print(f'INFO: img_size={self.img_size}, patch_shape={self.patch_shape}, stride={self.stride}')\n",
        "        processed_root_folder = processed_root_folder if processed_root_folder is not None else os.path.join(\n",
        "            root_folder, 'processed', problem)\n",
        "        processed_folder_path = os.path.join(processed_root_folder, '{}_{}'.format(*self.img_size), datatype,\n",
        "                                             'good' if datatype == 'train' else test_example)\n",
        "        if not os.path.exists(processed_folder_path): os.makedirs(processed_folder_path)\n",
        "        h5_path = os.path.join(processed_folder_path, 'dataset.h5')\n",
        "        if os.path.exists(h5_path):\n",
        "            t = datetime.now()\n",
        "            hdata = h5py.File(h5_path, mode='r')\n",
        "            self.data = hdata['data']\n",
        "            self.mask = hdata['mask']\n",
        "            # print('Data Loading Time {}'.format(datetime.now() - t))\n",
        "        else:\n",
        "            t = datetime.now()\n",
        "            # print('start processing the data')\n",
        "            # maybe  create a folder to preprocess all images in order to speedup the reading\n",
        "            assert datatype in ['train', 'test']\n",
        "            if datatype == 'train':\n",
        "                path_img = os.path.join(root_folder, problem, datatype, 'good')\n",
        "                path_mask = None\n",
        "            else:\n",
        "                assert test_example in ['color', 'cut', 'good', 'hole', 'thread', 'metal_contamination']\n",
        "                path_img, path_mask = os.path.join(root_folder, problem, datatype, test_example), os.path.join(\n",
        "                    root_folder, problem, 'ground_truth', test_example)\n",
        "                assert os.path.exists(path_mask)\n",
        "\n",
        "            self.data, self.mask = self.read_images(glob.glob(os.path.join(path_img, '*.png')),\n",
        "                                                    glob.glob(os.path.join(path_mask,\n",
        "                                                                           '*.png')) if path_mask is not None else path_mask)\n",
        "            with h5py.File(h5_path, mode='w') as hdata:\n",
        "                hdata['data'] = self.data\n",
        "                hdata['mask'] = self.mask\n",
        "            print('Data Loading Time {}'.format(datetime.now() - t))\n",
        "    def download(self,root, problem):\n",
        "        pass\n",
        "\n",
        "    def create_sample_list(self):\n",
        "        df = pd.DataFrame()\n",
        "        tmp = pd.DataFrame(dict(row=self.pm.center_list[:, 0], col=self.pm.center_list[:, 1]))\n",
        "        for i in range(self.data.shape[0]):\n",
        "            tmp['img_id'] = i\n",
        "            df = df.append(tmp, ignore_index=True)\n",
        "        return df\n",
        "\n",
        "    def read_images(self, img_paths, mask_paths=None):\n",
        "        data = []\n",
        "        mask = []\n",
        "        # if (mask_paths is not None) and (len(mask_paths)!=0): \n",
        "        parser = zip(img_paths, mask_paths) if (mask_paths is not None) and (\n",
        "                    len(mask_paths) == len(img_paths)) else img_paths\n",
        "        for ff in parser:\n",
        "            try:\n",
        "                fimg, fmask = ff\n",
        "            except:\n",
        "                fimg, fmask = (ff, None)\n",
        "            data.append(resize(rgb2gray(io.imread(fimg)), self.img_size))  # check to do it with PIL instead\n",
        "            if fmask is not None: mask.append(\n",
        "                resize(rgb2gray(io.imread(fmask)), self.img_size))  # check to do it with PIL instead\n",
        "        return np.asarray(data), np.asarray(mask)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ''' \n",
        "        # IMPORTANT\n",
        "        # aa = self.data[img_id]\n",
        "        # aa[col-20:col+20, row-15:row+15] = 0\n",
        "        example to make a fake hole on the image // missing part (possible test to do  as self supervised method)\n",
        "        '''\n",
        "        # add une rotation aleatoire \n",
        "        # rotation = np.random.choice(np.arange(10)*15)\n",
        "        img_id, row, col = self.read_image(index)\n",
        "        img = self.pm.get_patch(img=self.data[img_id], center_point=(row, col), angle=self.angle ).reshape(*self.patch_shape).astype(np.float32)\n",
        "        if self.datatype == 'test': \n",
        "            mask = self.pm.get_patch(img=self.mask[img_id], center_point=(row, col), angle=self.angle).reshape(*self.patch_shape).astype(np.float32)\n",
        "        if self.transform is not None:\n",
        "            timg = self.transform(img)\n",
        "            if self.datatype == 'test': \n",
        "                tmask = self.transform(mask)\n",
        "\n",
        "        if self.datatype == 'test':\n",
        "            # return rotation value\n",
        "            return timg, tmask#, rotation\n",
        "        else:\n",
        "            return timg\n",
        "\n",
        "    def read_image(self, index):\n",
        "        '''\n",
        "        '''\n",
        "        pass\n",
        "        info = self.dfinfo.iloc[index] # Id image original, coordinate row_patch, coordinate col_patch\n",
        "        img_id, row, col = info['img_id'], info['row'], info['col']\n",
        "        return img_id, row, col\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dfinfo.shape[0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAAe4tPeNBS6",
        "colab_type": "code",
        "outputId": "c1136643-ebb3-4f64-acb5-45991c9e47d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def run(datatype,angle=0,vflip=False,hflip=False,split='train'):\n",
        "    assert datatype in ['good', 'color', 'cut', 'good', 'hole', 'thread', 'metal_contamination']\n",
        "    dataset = ImageDataset(root_folder='/content/SSL-research/www',\n",
        "                           datatype='train' if datatype =='good' else 'test', img_size=(512,512),\n",
        "                           patch_shape=(32,32), stride=(16,16),\n",
        "                           test_example=datatype, sample_size=1000 if datatype =='good' else None,vflip=vflip,hflip=hflip, angle=angle,split=split)\n",
        "    \n",
        "    loader = DataLoader(dataset, shuffle=False, batch_size=128, num_workers=4, pin_memory=False)\n",
        "    X = []\n",
        "    for x  in loader:\n",
        "        if datatype =='good':\n",
        "            img = x\n",
        "            X.append(img)\n",
        "        else:\n",
        "            img, mask = x\n",
        "            mask = mask.reshape(mask.shape[0],-1).numpy()\n",
        "            mask[mask>0] = 1\n",
        "            i = np.where(mask.sum(axis=1)> 1 )[0]\n",
        "            X.append(img[i])\n",
        "            # return\n",
        "            # grid_img = utils.make_grid(img,nrow=4).permute(1, 2, 0)\n",
        "            # plt.imshow(grid_img)\n",
        "    return np.concatenate(X)\n",
        "\n",
        "def loop_run(split='test'):\n",
        "    if os.path.exists('dataset.h5'):\n",
        "        !rm -rf dataset.h5\n",
        "    with h5py.File(f'DATASET_{split}.h5',mode='w') as f:\n",
        "        for datatype in [ 'color', 'cut', 'good', 'hole', 'thread', 'metal_contamination']:\n",
        "            print(datatype)\n",
        "            group = f.create_group(datatype)\n",
        "            for angle in [0,15,30,45,60,75, 90, 105, 120, 150]:\n",
        "                print(angle)\n",
        "                x = run( datatype=datatype, angle=angle, split=split)\n",
        "                # return\n",
        "                group['angle{}'.format(angle)] = x  \n",
        "                # return\n",
        "loop_run(split='train')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "color\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "cut\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "good\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "hole\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "thread\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "metal_contamination\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCieuDgPIt3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "356b411e-b940-456b-9cf1-b8abe883dd2f"
      },
      "source": [
        "loop_run(split='test')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "color\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "cut\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "good\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "hole\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "thread\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n",
            "metal_contamination\n",
            "0\n",
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9TAIQg1KIro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}